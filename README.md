# 🧹 Layoffs Dataset Cleaning and Transformation | SQL

## 📌 Overview
This project focuses on cleaning and transforming a real-world layoffs dataset using SQL. The dataset contained duplicate entries, inconsistent text formats, null values, and poorly structured columns — all of which were addressed using structured SQL queries to prepare the data for accurate analysis.

## 🛠 Tools & Technologies Used
- SQL (MySQL / PostgreSQL / SQLite — whichever you used)
- DB Browser / SQL Workbench (if applicable)
- Layoffs Dataset (from Kaggle or public data source)

## 💡 What This Project Does
- Removed duplicate rows based on key attributes.
- Handled missing values by either removing or filling them with logical defaults.
- Standardized inconsistent text formats (like lowercase/uppercase issues, date formatting, country names, etc.)
- Optimized and cleaned column names and data types.
- Created a clean and structured version of the dataset ready for business analysis or dashboarding.

## 📁 Files Included
- `data cleaning project.sql` — SQL script file containing all data cleaning queries.
- `layoffs.csv` — Raw unprocessed dataset.
- `README.md` — Project documentation.

